{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHRwkgeT3g1P1Vt3mXR4Pk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThomasCMcLean/Lazy_AF/blob/main/Lazy_AF_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lazy_AF Workflow Part 2**\n",
        "\n",
        "This part of the workflow is designed to copy the highest ranked .json files  for each AlphaFold prediction from the designated Google Drive folder into the destination directory.\n",
        "\n",
        "It will then output a .csv table with a list of each interaction, the pTM, ipTM and ranking_confidence (0.2pTM + 0.8ipTM) for downstream analysis of your choosing. This is reliant on the file name and currently only works on two-protein interactions.\n",
        "\n",
        "**For details, refer to our manuscript:** *in prep*\n",
        "\n",
        "**Lazy_AF Part 1** can be found here : https://colab.research.google.com/drive/1a5d7xraEK4Iv3Ecmmjb1opnU5jwXRW_a#scrollTo=M_CoJNzed49A\n",
        "\n",
        "For more details checkout the [ColabFold GitHub](https://github.com/ThomasCMcLean/Lazy_AF)."
      ],
      "metadata": {
        "id": "govQ1XcjeYSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sys import version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\""
      ],
      "metadata": {
        "id": "mX3Dd2ZNeqq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2970ab63-1a1e-4ac4-d2ee-1942a30f89f8",
        "cellView": "form"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Input directories and copy top ranked JSON files to this location\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import shutil\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Source directory containing the JSON files\n",
        "source_directory = '/content/drive/MyDrive/RK2_results' #@param {type:\"string\"}\n",
        "\n",
        "# Destination directory for .json files and analysis\n",
        "destination_directory = '/content/drive/MyDrive/analysis' #@param {type:\"string\"}\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(destination_directory, exist_ok=True)\n",
        "\n",
        "# Define the pattern to match files\n",
        "pattern = '*_rank_001*.json'\n",
        "\n",
        "# Find files matching the pattern in the source directory\n",
        "matching_files = glob.glob(os.path.join(source_directory, pattern))\n",
        "\n",
        "# Copy matching files to the destination directory\n",
        "for file_path in matching_files:\n",
        "    shutil.copy(file_path, destination_directory)\n",
        "\n"
      ],
      "metadata": {
        "id": "GMqFOU0SeAEO",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2359a7f5-95a3-4b71-a8db-d22529d6e75c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Name and produce your output .csv file\n",
        "\n",
        "# final file name\n",
        "csv_name = 'Output' #@param {type:\"string\"}\n",
        "\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Function to extract pTM and ipTM values from a JSON file\n",
        "def extract_ptm_iptm(json_file):\n",
        "    with open(json_file, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    ptm = data['ptm']\n",
        "    iptm = data['iptm']\n",
        "\n",
        "    return {'ptm': ptm, 'iptm': iptm}\n",
        "\n",
        "# Directory where your JSON files are located\n",
        "json_folder = destination_directory  # Replace with the actual folder path\n",
        "csv_file_path = os.path.join(json_folder, csv_name + '.csv')\n",
        "\n",
        "# List all JSON files in the folder\n",
        "json_files = [os.path.join(json_folder, file) for file in os.listdir(json_folder) if file.endswith('.json')]\n",
        "\n",
        "# Create an empty data frame to store the extracted data\n",
        "result_data = pd.DataFrame(columns=['Protein_1', 'Protein_2', 'pTM', 'ipTM'])\n",
        "\n",
        "# Iterate through the list of JSON files\n",
        "for json_file_path in json_files:\n",
        "    # Extract the base name without extension\n",
        "    file_name = os.path.splitext(os.path.basename(json_file_path))[0]\n",
        "\n",
        "    # Extract everything before the asterix\n",
        "    file_name_parts = file_name.split('*')\n",
        "    file_name_short = file_name_parts[0]\n",
        "\n",
        "    # Call the function to extract PTM and IPTM values\n",
        "    ptm_iptm_values = extract_ptm_iptm(json_file_path)\n",
        "\n",
        "    # Access PTM and IPTM values\n",
        "    ptm_value = ptm_iptm_values['ptm']\n",
        "    iptm_value = ptm_iptm_values['iptm']\n",
        "\n",
        "    # Split the first column using \"-\"\n",
        "    protein_names = file_name_short.split('-')\n",
        "\n",
        "    # Check if there are enough elements in protein_names\n",
        "    if len(protein_names) >= 2:\n",
        "       # Create a data frame for the current JSON file\n",
        "        file_data = pd.DataFrame({\n",
        "            'Protein_1': [protein_names[0]],\n",
        "           'Protein_2': [protein_names[1]],\n",
        "           'pTM': [ptm_value],\n",
        "            'ipTM': [iptm_value],\n",
        "            'Ranking_confidence': [0.2 * ptm_value + 0.8 * iptm_value]\n",
        "        })\n",
        "\n",
        "\n",
        "    # Append the current file's data to the result_data data frame\n",
        "    result_data = pd.concat([result_data, file_data], ignore_index=True)\n",
        "\n",
        "# Save the data to a CSV file\n",
        "result_data.to_csv(csv_file_path, index=False)"
      ],
      "metadata": {
        "id": "3bUvkQ7sZYFj",
        "cellView": "form"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}